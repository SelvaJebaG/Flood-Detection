{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42739110-ba58-4850-84db-215a87e3302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "import rasterio\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60e7ee-f5b6-441d-816a-882aeea8c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = 'path'\n",
    "path_training_images = 'path'\n",
    "path_testing_images = 'path'\n",
    "def image_label(product_id):\n",
    "    rootdir = \"path\"\n",
    "    pd = product_id.split(\"_\")\n",
    "    pd = pd[3] + \"_\" + pd[4] + \"_\" + pd[5] + \"_\" + pd[6]    \n",
    "    json_data=open(rootdir + pd +\"/stac.json\", \"rb\")\n",
    "    jdata = json.load(json_data)\n",
    "    flood = jdata[\"properties\"][\"FLOODING\"]\n",
    "    if (flood == \"False\"):\n",
    "        image_label = 0\n",
    "    else:\n",
    "        image_label = 1\n",
    "    \n",
    "    return image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5581fbc-7a09-4575-a11f-9311a7103294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_name(path):\n",
    "    \n",
    "    json_data=open(path+\"/stac.json\", \"rb\")\n",
    "    jdata = json.load(json_data)\n",
    "    \n",
    "    return  jdata['id']\n",
    "    def load_data():\n",
    "    \n",
    "    data = [] \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in imagelist:\n",
    "        try:\n",
    "            product_id = product_name(folder)\n",
    "            print(f\"Processing {product_id} image product\")\n",
    "            label = image_label(product_id)\n",
    "        \n",
    "            # Open the img\n",
    "            image = cv2.imread(folder + \"/stack.tif\")\n",
    "            # Append the image and its corresponding label to the output\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "        \n",
    "        \n",
    "    data.append([images, labels])     \n",
    "\n",
    "    return images, labels\n",
    "    imagelist = []\n",
    "rootdir = path_training_images\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        imagelist.append(d)\n",
    "        \n",
    "        \n",
    "print(f\"The number of training samples is currently = {len(imagelist)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b368b7d-ec25-4edd-a2bc-0d4ade28ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a94153-2f10-44d0-8b26-ab87c7222f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_name(path):\n",
    "    \n",
    "    json_data=open(path+\"/stac.json\", \"rb\")\n",
    "    jdata = json.load(json_data)\n",
    "    \n",
    "    return  jdata['id']\n",
    "    def load_data():\n",
    "    \n",
    "    data = [] \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in imagelist:\n",
    "        try:\n",
    "            product_id = product_name(folder)\n",
    "            print(f\"Processing {product_id} image product\")\n",
    "            label = image_label(product_id)\n",
    "        \n",
    "            # Open the img\n",
    "            image = cv2.imread(folder + \"/stack.tif\")\n",
    "            # Append the image and its corresponding label to the output\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "        \n",
    "        \n",
    "    data.append([images, labels])     \n",
    "\n",
    "    return images, labels\n",
    "    imagelist = []\n",
    "rootdir = path_testing_images\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        imagelist.append(d)\n",
    "        \n",
    "        \n",
    "print(f\"The number of testing samples is currently = {len(imagelist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a799ee7-e6f2-475d-af1b-310982a23582",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33058cfa-e432-405e-8bda-64489612967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = torch.tensor(images).permute(0, 3, 1, 2)\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = FloodDataset(train_images, train_labels)\n",
    "test_dataset = FloodDataset(test_images, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Swish activation\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Hierarchical Multi-Attention block\n",
    "class HierarchicalMultiAttention(nn.Module):\n",
    "    def __init__(self, in_dim, key_dim=64):\n",
    "        super(HierarchicalMultiAttention, self).__init__()\n",
    "        self.W_q = nn.Linear(in_dim, key_dim)\n",
    "        self.W_k = nn.Linear(in_dim, key_dim)\n",
    "        self.W_v = nn.Linear(in_dim, key_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "        d_k = K.size(-1)\n",
    "        attn = self.softmax(Q @ K.transpose(-2, -1) / np.sqrt(d_k))\n",
    "        return attn @ V\n",
    "\n",
    "# HMA-EfficientNetV2 model\n",
    "class HMAEfficientNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(HMAEfficientNetV2, self).__init__()\n",
    "        base_model = models.efficientnet_v2_s(weights='DEFAULT')\n",
    "        self.features = base_model.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.swish = Swish()\n",
    "        self.hma_blocks = nn.ModuleList([\n",
    "            HierarchicalMultiAttention(1280),\n",
    "            HierarchicalMultiAttention(1280),\n",
    "            HierarchicalMultiAttention(1280)\n",
    "        ])\n",
    "        self.concat_fc = nn.Linear(3 * 64, 128)\n",
    "        nn.init.kaiming_uniform_(self.concat_fc.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(self.concat_fc.bias)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        features = []\n",
    "        for hma in self.hma_blocks:\n",
    "            hma_out = hma(x.unsqueeze(1))\n",
    "            features.append(hma_out.squeeze(1))\n",
    "        hma_cat = torch.cat(features, dim=-1)\n",
    "        fhma = self.swish(self.concat_fc(hma_cat))\n",
    "        out = self.fc(fhma)\n",
    "        return out\n",
    "\n",
    "model = HMAEfficientNetV2()\n",
    "\n",
    "# Loss function with label smoothing and regularization\n",
    "def custom_loss(y_pred, y_true, smoothing=0.1, alpha=0.9, reg_lambda=1e-4):\n",
    "    num_classes = y_pred.size(1)\n",
    "    y_true = F.one_hot(y_true, num_classes).float()\n",
    "    y_smooth = (1 - smoothing) * y_true + smoothing / num_classes\n",
    "    ce_loss = -torch.sum(y_smooth * F.log_softmax(y_pred, dim=1), dim=1).mean()\n",
    "    l2_reg = sum(torch.norm(p)**2 for p in model.parameters())\n",
    "    return alpha * ce_loss + (1 - alpha) * reg_lambda * l2_reg\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = custom_loss(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    
    "all_preds = []\n",
    "all_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        outputs = model(x_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"Precision (%): {100 * precision:.1f}\")\n",
    "print(f\"Recall (%):    {100 * recall:.1f}\")\n",
    "print(f\"Accuracy (%):  {100 * accuracy:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3687a0-dd9a-42d6-8653-b4ebead3a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis\n",
    "background = next(iter(DataLoader(train_dataset, batch_size=100, shuffle=True)))[0]\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            return F.softmax(self.model(x), dim=1)\n",
    "wrapped_model = WrappedModel(model)\n",
    "explainer = shap.DeepExplainer(wrapped_model, background)\n",
    "sample_inputs, _ = next(iter(DataLoader(test_dataset, batch_size=10, shuffle=False)))\n",
    "shap_values = explainer.shap_values(sample_inputs)\n",
    "mean_shap_per_channel = np.abs(shap_values[1]).mean(axis=(0, 2, 3))\n",
    "for i, val in enumerate(mean_shap_per_channel):\n",
    "    print(f\"Channel {i}: Mean SHAP Value = {val:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
